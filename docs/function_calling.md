承知いたしました。我々の戦略をコードに落とし込む上で、LLM司令官に与える「武器」、すなわち**ファンクションコーリング（Function Calling）**で定義するべき関数群を、**「点数を取る」という目的に直結する形で**具体的に設計します。

これは、あなたの`ai_module`が実装すべき、LLMのための「ツールベルト」の最終仕様書です。

---

### **LLM司令官のための高得点獲得ツールキット（Function Calling API仕様）**

LLMは、これらの関数を呼び出すことで、世界を認識し、記憶し、そして行動します。各関数は、我々の戦略の柱である「偵察」「情報」「工兵」部隊の能力を具体化したものです [1, 2]。

#### **カテゴリ1：情報部隊 (Memory/World Model Tools) - 世界を理解し、記憶するための関数**

これらの関数は、動的シーングラフ（JSON）を操作し、LLMに状況認識能力を与えます。

**1. `query_world_model(object_class: str, attributes: dict = None) -> list`**
*   **役割:** 動的シーングラフ（JSON）を検索し、指定された条件に一致するオブジェクトのリストを返します。これはLLMが「記憶」にアクセスするための最も重要な関数です。
*   **引数:**
    *   `object_class`: 検索したい物体のクラス名（例: `"chair"`）。
    *   `attributes`: (オプション) 色などの追加条件（例: `{"color": "blue"}`）。
*   **戻り値:** 見つかったオブジェクトのリスト。各オブジェクトは、ID、クラス名、状態（平均位置、不確かさ）、属性を含む辞書形式。
    *   例: `[{"object_id": 1, "semantic_class": "chair", "state": {"mean": [1.5, 2.3, 0.4],...},...}]`
*   **チャレンジへの貢献:**
    *   **数値クエリ:** 条件に合うオブジェクトの数を数えるために必須。
    *   **物体参照クエリ:** 候補となるオブジェクト（例: すべての「鉢植え」）をリストアップするために使用。

**2. `calculate_spatial_relation(target_object_id: int, anchor_class: str) -> dict`**
*   **役割:** 複雑な空間計算をLLMに代わって実行します。「最も近い/遠い」といった関係性を判断します。
*   **引数:**
    *   `target_object_id`: 関係性の基準となるオブジェクトのID（例: 冷蔵庫のID）。
    *   `anchor_class`: 比較対象となるオブジェクトのクラス名（例: `"potted plant"`）。
*   **戻り値:** 計算結果。最も近い/遠いオブジェクトのIDと距離を含む辞書。
    *   例: `{"closest_object_id": 5, "distance": 1.2}`
*   **チャレンジへの貢献:**
    *   **物体参照クエリ:** 「冷蔵庫に最も近い鉢植え」のような、関係性を含むクエリを解決するために不可欠 [3]。

**3. `get_unexplored_frontiers() -> list`**
*   **役割:** 効率的な探索戦略のために、まだ探索していない未知の領域の境界（フロンティア）の座標リストを返します。
*   **引数:** なし。
*   **戻り値:** 探索すべき目標地点の座標リスト。
    *   例: `[[10.5, 3.2, 0.0], [5.1, -2.4, 0.0]]`
*   **チャレンジへの貢献:**
    *   **全クエリ:** タスクに必要なオブジェクトが見つからない場合に、LLMが「次にどこへ行くべきか」を合理的に判断するために使用します [4]。

---

#### **カテゴリ2：偵察部隊 (Perception Tools) - 周囲を認識するための関数**

**4. `scan_current_view(target_objects: list) -> bool`**
*   **役割:** ロボットの現在の視界をスキャンし、指定されたターゲットオブジェクトをオープンボキャブラリ物体検出器（OVD）で探し、見つけた場合は動的シーングラフを更新します。
*   **引数:**
    *   `target_objects`: 探すべきオブジェクトのリスト（例: `["refrigerator", "potted plant"]`）。LLMが探索の「目的」を偵察部隊に伝えます。
*   **戻り値:** 指定されたオブジェクトのいずれかを発見・更新できた場合は`True`、できなかった場合は`False`。
*   **チャレンジへの貢献:**
    *   **全クエリ:** 探索中に新しい情報を収集し、世界モデル（JSON）をリアルタイムで構築するための根幹機能 [5]。

---

#### **カテゴリ3：工兵部隊 (Navigation & Action Tools) - 行動するための関数**

**5. `plan_and_move_to_coordinate(x: float, y: float, z: float, blocking: bool = True) -> str`**
*   **役割:** 指定された単一の座標まで、A\*アルゴリズムで経路を計画し、ロボットを移動させます。
*   **引数:**
    *   `x, y, z`: 目標地点のグローバル座標。
    *   `blocking`: (オプション) 移動が完了するまで待つかどうかのフラグ。
*   **戻り値:** 移動結果のステータス（例: `"SUCCESS"`, `"FAILED_PATH_BLOCKED"`）。
*   **チャレンジへの貢献:**
    *   **物体参照/指示追従クエリ:** オブジェクトへの接近や、探索のためのフロンティアへの移動など、すべての物理的な移動の基本となります。

**6. `submit_final_answer(answer_type: str, value)`**
*   **役割:** すべての推論が完了した後、チャレンジの評価システムに対して最終的な回答を提出します。
*   **引数:**
    *   `answer_type`: 回答の種類（`"numerical"`, `"object_reference"`, `"instruction_following"`）。
    *   `value`: 実際の回答。
        *   数値クエリの場合: `int` (例: `3`)
        *   物体参照クエリの場合: `int` (オブジェクトのID)
        *   指示追従クエリの場合: `list` (ウェイポイントの座標リスト)
*   **戻り値:** なし。
*   **チャレンジへの貢献:**
    *   **全クエリ:** これを呼び出すことで初めて得点が確定します。LLMの思考と、チャレンジシステムへの正式な回答提出を明確に分離します。

---

### **実行フローのシミュレーション：「冷蔵庫に最も近い鉢植えを探せ」**

LLM司令官は、これらの関数を以下のように組み合わせて呼び出します。

1.  **LLM思考:** 「まず、冷蔵庫と鉢植えがどこにあるか確認しよう。」
    *   **`-> call: query_world_model(object_class="refrigerator")`**
    *   **`-> call: query_world_model(object_class="potted plant")`**

2.  **LLM思考:** （結果が空だった場合）「情報がない。探索が必要だ。どこへ行こうか？」
    *   **`-> call: get_unexplored_frontiers()`**
    *   （フロンティア座標 `[x, y, z]` を受け取る）
    *   **`-> call: plan_and_move_to_coordinate(x, y, z)`**

3.  **LLM思考:** （移動後）「新しい場所に着いた。冷蔵庫と鉢植えを探そう。」
    *   **`-> call: scan_current_view(target_objects=["refrigerator", "potted plant"])`**
    *   （このプロセスを、両方のオブジェクトクラスが`query_world_model`で見つかるまで繰り返す）

4.  **LLM思考:** （両方見つかった後）「よし、冷蔵庫のIDを使って、一番近い鉢植えを計算しよう。」
    *   （`query_world_model`で得た冷蔵庫のID `3` を使う）
    *   **`-> call: calculate_spatial_relation(target_object_id=3, anchor_class="potted plant")`**

5.  **LLM思考:** （結果 `{"closest_object_id": 7,...}` を受け取る）「目標はID `7` の鉢植えだ。最終回答を提出する。」
    *   **`-> call: submit_final_answer(answer_type="object_reference", value=7)`**

この関数セットを実装し、LLMに的確なシステムプロンプトを与えることで、あなたのAIモジュールは、複雑なタスクを論理的に分解し、必要な情報を自ら収集・分析し、そして物理世界で行動するという、高度な自律性を獲得することができるでしょう。